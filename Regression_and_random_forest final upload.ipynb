{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, cross_val_score \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setpvalue(series):\n",
    "    return (series<0.01).replace({True:'*',False:''}) + (series<0.05).replace({True:'*',False:''}) + (series<0.1).replace({True:'*',False:''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sp # for spearman correlation\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats # for logistic regression\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(year,spearmanflag):   \n",
    "   \n",
    "    # Read raw file\n",
    "    raw = pd.read_csv('dataset'+str(year)+'.csv') \n",
    "    \n",
    "    # Fill missing value: years, ages with mean\n",
    "    for columnname in raw.iloc[:,7:15].columns:\n",
    "        meanvalue = raw[raw[columnname] !=0][columnname].mean()\n",
    "        raw[columnname] = raw[columnname].replace({0:meanvalue})\n",
    "    \n",
    "    \n",
    "    dataset_X = pd.concat([raw.iloc[:,7],raw.iloc[:,9:11], raw.iloc[:,12:-4],raw.iloc[:,-2:]], axis = 1)\n",
    "    dataset_y = raw.iloc[:,2]\n",
    "    \n",
    "    glm = sm.OLS(dataset_y, dataset_X)\n",
    "    resultmodel = glm.fit()\n",
    "    \n",
    "    coeffandp = pd.concat([pd.DataFrame(resultmodel.params, columns = [year]),\\\n",
    "                           pd.DataFrame(resultmodel.pvalues, columns = ['pvalue'])] , axis  = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coeffandp['sx'] = np.where(coeffandp.pvalue < 0.10, '*', '')\n",
    "    coeffandp['s5'] = np.where(coeffandp.pvalue < 0.05, '*', '')\n",
    "    coeffandp['s1'] = np.where(coeffandp.pvalue < 0.01, '*', '')\n",
    "    coeffandp[str(year)+'mk'] = coeffandp['sx'] + coeffandp['s5'] + coeffandp['s1']\n",
    "    \n",
    "    coeffandp.drop(['sx','s5','s1','pvalue'], inplace = True, axis =1)\n",
    "    \n",
    "    if (spearmanflag == 1):\n",
    "        \n",
    "        fulldata = pd.concat([dataset_y,dataset_X], axis = 1)\n",
    "\n",
    "        spearmanresult = sp.spearmanr(fulldata)\n",
    "\n",
    "        spearmandf = pd.DataFrame(spearmanresult.correlation, index = fulldata.columns)\n",
    "        spearmandf.columns = fulldata.columns\n",
    "        spearmandfp = pd.DataFrame(spearmanresult.pvalue, index = fulldata.columns)\n",
    "        spearmandfp.columns = fulldata.columns\n",
    "                                      \n",
    "        return coeffandp, resultmodel, spearmandf, spearmandfp\n",
    "    else:\n",
    "        return coeffandp, resultmodel\n",
    "                                      \n",
    "                                \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefdict = {}\n",
    "modeldict = {}\n",
    "spearmandict = {}\n",
    "\n",
    "for startingyear in range(960,1280,10):\n",
    "\n",
    "    coeffdf, model, spearmandf, spearmandfp = analysis(startingyear,1)\n",
    "    \n",
    "    coefdict[startingyear] = coeffdf\n",
    "    modeldict[startingyear] = model\n",
    "    spearmandict[startingyear] = (spearmandf,spearmandfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "\n",
    "for year in range(960,1280,10):\n",
    "    stats ={}\n",
    "    stats['R-squared'] = modeldict[year].rsquared\n",
    "    stats['Adjusted R-squared'] = modeldict[year].rsquared_adj\n",
    "    stats['F-statistic'] = modeldict[year].fvalue\n",
    "    stats['F-stat p-value'] = modeldict[year].f_pvalue\n",
    "    \n",
    "    dflist.append(pd.DataFrame(stats,index =[year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# R-squared table\n",
    "\n",
    "significantvariablenumber = {}\n",
    "for startingyear in range(960,1280,10):\n",
    "    significantvariablenumber[startingyear] = len(coefdict[startingyear][coefdict[startingyear].iloc[:,-1] != ''])\n",
    "    \n",
    "    \n",
    "rsquare = pd.concat(dflist)\n",
    "rsquare.iloc[:,-1] = setpvalue(rsquare.iloc[:,-1])\n",
    "pd.concat([rsquare,pd.DataFrame(significantvariablenumber, index = ['Number of Variable found significant']).T],axis =1).to_csv('newrsquare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Geographic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significantlu  ={}\n",
    "for startingyear in range(960,1280,10):\n",
    "    tempdf = coefdict[startingyear][6:35]\n",
    "    significantlu[startingyear] = len(tempdf[tempdf.iloc[:,-1] != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for startingyear in range(960,1280,10):\n",
    "    \n",
    "    convertingdict = {}\n",
    "\n",
    "    convertingdict['Longitude'] = coefdict[startingyear].iloc[4:6].iloc[0,0]\n",
    "    convertingdict['Lonp'] = coefdict[startingyear].iloc[4:6].iloc[0,1]\n",
    "    convertingdict['Latitude'] = coefdict[startingyear].iloc[4:6].iloc[1,0]\n",
    "    convertingdict['Ltp'] = coefdict[startingyear].iloc[4:6].iloc[1,1]\n",
    "\n",
    "    dflist.append(pd.DataFrame(convertingdict,index = [startingyear]))\n",
    "lonlatdf = pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo = pd.concat([pd.DataFrame(significantlu, index = ['Number of Significant Lu']).T,lonlatdf],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo.to_csv('georesult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloodline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloodroutes = ['entry_8','entry_59','entry_60','entry_62','entry_118']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for startingyear in range(960,1280,10):\n",
    "    print (coefdict[startingyear].T[bloodroutes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "\n",
    "for startingyear in range(960,1280,10):\n",
    "    tempdf = coefdict[startingyear].T[bloodroutes].T\n",
    "    convertingdict ={}\n",
    "    for i in range(len(bloodroutes)):\n",
    "        convertingdict[bloodroutes[i]] = tempdf.iloc[i,0]\n",
    "        convertingdict[bloodroutes[i]+'p'] = tempdf.iloc[i,1]\n",
    "\n",
    "    dflist.append( pd.DataFrame(convertingdict, index = [startingyear]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dflist).to_csv('bloodresult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jinshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliteroutes = ['entry_36','entry_165']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "\n",
    "for startingyear in range(960,1280,10):\n",
    "    tempdf = coefdict[startingyear].T[eliteroutes].T\n",
    "    convertingdict ={}\n",
    "    for i in range(len(eliteroutes)):\n",
    "        convertingdict[eliteroutes[i]] = tempdf.iloc[i,0]\n",
    "        convertingdict[eliteroutes[i]+'p'] = tempdf.iloc[i,1]\n",
    "\n",
    "    dflist.append( pd.DataFrame(convertingdict, index = [startingyear]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dflist).to_csv('eliteresult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ['status','nemesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "\n",
    "for startingyear in range(960,1280,10):\n",
    "    tempdf = coefdict[startingyear].T[network].T\n",
    "    convertingdict ={}\n",
    "    for i in range(len(network)):\n",
    "        convertingdict[network[i]] = tempdf.iloc[i,0]\n",
    "        convertingdict[network[i]+'p'] = tempdf.iloc[i,1]\n",
    "\n",
    "    dflist.append( pd.DataFrame(convertingdict, index = [startingyear]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dflist).to_csv('networkresult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conninput = sqlite3.connect(\"edgelist.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforestandreturn(year):\n",
    "    \n",
    "    # Read raw file\n",
    "    raw = pd.read_csv('dataset'+str(year)+'.csv') \n",
    "    \n",
    "    # Fill missing value: years, ages with mean\n",
    "    for columnname in raw.iloc[:,7:15].columns:\n",
    "        meanvalue = raw[raw[columnname] !=0][columnname].mean()\n",
    "        raw[columnname] = raw[columnname].replace({0:meanvalue})\n",
    "    \n",
    "    \n",
    "    dataset_X = pd.concat([raw.iloc[:,7],raw.iloc[:,9:11], raw.iloc[:,12:-4],raw.iloc[:,-2:]], axis = 1)\n",
    "    dataset_y = raw.iloc[:,2]\n",
    "\n",
    "    # Perform Grid-Search \n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3,20),\n",
    "            'n_estimators': (10, 50, 100, 1000),\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "    grid_result = gsc.fit(dataset_X, dataset_y)\n",
    "    best_params = grid_result.best_params_\n",
    "\n",
    "    sel = SelectFromModel(RandomForestRegressor(max_depth=best_params[\"max_depth\"],\n",
    "                                n_estimators=best_params[\"n_estimators\"],\n",
    "                                random_state=False, verbose=False))\n",
    "    sel.fit(dataset_X, dataset_y)\n",
    "\n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"],\n",
    "                                n_estimators=best_params[\"n_estimators\"],\n",
    "                                random_state=False, verbose=False)\n",
    "    # Perform K-Fold CV\n",
    "    scores = cross_val_score(rfr, dataset_X, dataset_y, cv=10, scoring='neg_mean_absolute_error')\n",
    "    predictions = cross_val_predict(rfr, dataset_X,dataset_y, cv=10)\n",
    "    MSE = metrics.mean_squared_error(dataset_y, predictions)\n",
    "\n",
    "    #    return predictions\n",
    "    \n",
    "    rfr.fit(dataset_X, dataset_y)\n",
    "    \n",
    "    return MSE, pd.DataFrame(rfr.feature_importances_, index = dataset_X.columns, columns = [year]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connoutput =  sqlite3.connect(\"gini_finalR.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msedict = {}\n",
    "ginidict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for startingyear in range(960,1280,10):\n",
    "    \n",
    "    if startingyear in msedict:\n",
    "        continue\n",
    "    \n",
    "    print('processing '+str(startingyear))\n",
    "    \n",
    "    mse, gini = randomforestandreturn(startingyear)\n",
    "\n",
    "    #gini.to_sql('gini'+str(startingyear), con=connoutput, if_exists='replace')\n",
    "    \n",
    "    msedict[startingyear] = mse\n",
    "    ginidict[startingyear] = gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msetable = pd.DataFrame(msedict, ['mse']).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msetable['sd'] = np.sqrt(msetable['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msetable.to_csv('newmse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertingdict ={}\n",
    "\n",
    "for startingyear in range(960,1280,10):\n",
    "\n",
    "    convertingdict[startingyear] = ginidict[startingyear].T.sort_values(by = startingyear, ascending = False).index[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(convertingdict, index = range(1,11)).T.to_csv('giniresult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(msedict, index = ['mse']).T.to_csv('mse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginis = {}\n",
    "for year in range(960,1280,10):\n",
    "    ginis[year]= pd.read_sql_query(\"SELECT * FROM gini\"+str(year), \n",
    "                         sqlite3.connect('gini_finalR.db')).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflis = []\n",
    "for year in range(960,1280,10):\n",
    "\n",
    "    tempdf = ginis[year].T.sort_values(by = 0, ascending = False).iloc[1:11].reset_index()\n",
    "    tempdf.columns = [str(year)+'+factor',str(year)+'+gini']\n",
    "    dflis.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat(dflis, axis =1).to_csv('ginipresent10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for year in coefdict:\n",
    "    dflist.append(coefdict[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffull = pd.concat(dflist, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffull.to_csv('coefficient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsondict = {}\n",
    "\n",
    "for year in range(960,1280,10):\n",
    "\n",
    "    raw = pd.read_csv('dataset'+str(year)+'.csv') \n",
    "    \n",
    "    pearsondict[year]=stats.pearsonr(raw.iloc[:,-2],raw.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pearsondict, index = ['corr','p-value']).T.to_csv('nemesis-status-correlation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(960,1280,10):\n",
    "\n",
    "    raw = pd.read_csv('dataset'+str(year)+'.csv') \n",
    "    \n",
    "    print(raw.iloc[:,-2])\n",
    "    print (raw.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
